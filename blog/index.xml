<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on Stephen Finucane (Fin-oo-can)</title>
    <link>https://that.guru/blog/</link>
    <description>Recent content in Blogs on Stephen Finucane (Fin-oo-can)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-IE</language>
    <copyright>This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.</copyright>
    <lastBuildDate>Fri, 15 Jul 2016 11:26:37 +0100</lastBuildDate>
    <atom:link href="https://that.guru/blog/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>GNU Autotest</title>
      <link>https://that.guru/blog/gnu-autotest/</link>
      <pubDate>Fri, 15 Jul 2016 11:26:37 +0100</pubDate>
      
      <guid>https://that.guru/blog/gnu-autotest/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://www.gnu.org/software/autoconf/manual/autoconf-2.67/html_node/Using-Autotest.html#Using-Autotest&#34;&gt;GNU Autotest&lt;/a&gt; is a test framework that, together with supporting
scripts and unit test files, can unit test an application. Autotest is part of
the &lt;a href=&#34;http://www.gnu.org/savannah-checkouts/gnu/automake/manual/html_node/Autotools-Introduction.html&#34;&gt;Autotools&lt;/a&gt; library, a.k.a. the &lt;a href=&#34;http://en.wikipedia.org/wiki/GNU_build_system&#34;&gt;GNU Build System&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The Autotest scripts execute unit tests by making shell-like calls to
utilities, Python scripts and C unit test applications, and comparing their
return values (exit code, stdout and stderr) to predefined values. To do this,
Autotest defines a number of &lt;a href=&#34;http://en.wikipedia.org/wiki/M4_(computer_language)http://en.wikipedia.org/wiki/M4_(computer_language)&#34;&gt;M4&lt;/a&gt;  macros, such as &lt;code&gt;AT_INIT&lt;/code&gt; and
&lt;code&gt;AT_CLEANUP&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;An example of a test is given below. This test is from the &lt;a href=&#34;http://wiki.ir.intel.com/sw/index.php/OVS&#34;&gt;Open vSwitch&lt;/a&gt;
project, and tests the resubmit action in the datapath.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;AT_SETUP([ofproto-dpif - resubmit])
OVS_VSWITCHD_START
AT_DATA([flows.txt], [dnl
table=0 in_port=1 priority=1000 icmp actions=output(10),resubmit(2),\
output(19),resubmit(3),output(21)
table=0 in_port=2 priority=1500 icmp actions=output(11),resubmit(,1),\
output(16),resubmit(2,1),output(18)
table=0 in_port=3 priority=2000 icmp actions=output(20)
table=1 in_port=1 priority=1000 icmp actions=output(12),resubmit(4,1),\
output(13),resubmit(3),output(15)
table=1 in_port=2 priority=1500 icmp actions=output(17),resubmit(,2)
table=1 in_port=3 priority=1500 icmp actions=output(14),resubmit(,2)
])
AT_CHECK([ovs-ofctl add-flows br0 flows.txt])
AT_CHECK([ovs-appctl ofproto/trace br0 &#39;in_port(1),eth(src=50:54:00:00:00:05,\
dst=50:54:00:00:00:07),eth_type(0x0800),ipv4(src=192.168.0.1,dst=192.168.0.2,\
proto=1,tos=0,ttl=128,frag=no),icmp(type=8,code=0)&#39;], [0], [stdout])
AT_CHECK([tail -1 stdout], [0],
  [Datapath actions: 10,11,12,13,14,15,16,17,18,19,20,21
])
OVS_VSWITCHD_STOP
AT_CLEANUP
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;macros&#34;&gt;Macros&lt;/h2&gt;

&lt;h3 id=&#34;m4-macros&#34;&gt;m4 macros&lt;/h3&gt;

&lt;dl&gt;
  &lt;dt&gt;&lt;code&gt;m4_define([name], [substitution])&lt;/code&gt;&lt;/dt&gt;
  &lt;dd&gt;Substitutes the word(s) given by name with the text given in substitution&lt;/dd&gt;
  &lt;dt&gt;&lt;code&gt;m4_if([name], [value], [execution])&lt;/code&gt;&lt;/dt&gt;
  &lt;dd&gt;If the value of the name variable equals that of the value variable, then
  execute execution&lt;/dd&gt;
&lt;/dl&gt;

&lt;h3 id=&#34;autotest-macros&#34;&gt;Autotest macros&lt;/h3&gt;

&lt;p&gt;Autotest macros are just predefined M4 macros. There are a number of them,
including:&lt;/p&gt;

&lt;dl&gt;
  &lt;dt&gt;&lt;code&gt;AT_SETUP(title)&lt;/code&gt;&lt;/dt&gt;
  &lt;dd&gt;Begin a test group named title. This title is really the identifier of
  the test group, used in quiet and verbose outputs. It should be short, but
  descriptive.&lt;/dd&gt;
  &lt;dt&gt;&lt;code&gt;AT_CHECK(commands, [status = 0], [stdout], [stderr])&lt;/code&gt;&lt;/dt&gt;
  &lt;dd&gt;Execute a test by performing given shell commands. These commands should
  normally exit with status, while producing expected stdout and stderr
  contents.&lt;/dd&gt;
  &lt;dt&gt;&lt;code&gt;AT_CLEANUP()&lt;/code&gt;&lt;/dt&gt;
  &lt;dd&gt;End a test group.&lt;/dd&gt;
&lt;/dl&gt;

&lt;h3 id=&#34;additional-macros&#34;&gt;Additional macros&lt;/h3&gt;

&lt;p&gt;There are many additional macros available to use. For a list of these, it&amp;rsquo;s
probably best to check out the official &lt;a href=&#34;http://www.gnu.org/software/autoconf/manual/autoconf-2.64/html_node/Writing-Testsuites.html#Writing-Testsuites&#34;&gt;GNU Autotest Manual&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;writing-a-sample-test&#34;&gt;Writing a sample test&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;rdquo;&amp;hellip;to learn and not to do is really not to learn. To know and not to do is
really not to know.&amp;ldquo;, Stephen R. Covey&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The best way to learn this stuff is to &lt;em&gt;do it&lt;/em&gt;. As such, we&amp;rsquo;re going to write a
sample test script that will explain the basic functionality of the Autotest
framework.&lt;/p&gt;

&lt;h3 id=&#34;what-we-want-to-achieve&#34;&gt;What we want to achieve&lt;/h3&gt;

&lt;p&gt;We want to test the &lt;code&gt;cat&lt;/code&gt; application. As with most shell applications, this
application provides an awful lot of functionality. We&amp;rsquo;re going to test only a
small subset of it&amp;rsquo;s functionality, and ignore all the other options and the
flags available to us. As such, we want to check that the following features
work as expected:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;cat&lt;/code&gt; prints an error message for a non-existing file&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cat&lt;/code&gt; prints nothing for an empty, existing file&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cat&lt;/code&gt; prints some output for a non-empty, existing file&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;initial-setup&#34;&gt;Initial setup&lt;/h3&gt;

&lt;p&gt;The first thing we should do is declare our own macro to place tests in. This
will act as a &lt;em&gt;function&lt;/em&gt; of sorts and allow us to call the tests at once or
from another file (plus it acts as a container to illustrate the difference in
different files). To do this, add the following code in a file called
&lt;code&gt;mytest.at&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;m4_define([MYTEST_CHECK_CAT], [])

MYTEST_CHECK_CAT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This works pretty straight-forwardly. When typed, the keyword
&lt;code&gt;MYTEST_CHECK_CAT&lt;/code&gt; on the bottom line will be replaced with the lines in the
second parameter of the macro (currently none). Obviously, in order to make
this useful, we need something in the second parameter like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;m4_define([MYTEST_CHECK_CAT], [
  AT_BANNER([])
  AT_SETUP([])
  AT_CHECK([], [], [], [])
  AT_CLEANUP
])

MYTEST_CHECK_CAT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Replace the text in &lt;code&gt;mytest.at&lt;/code&gt; with the above code. You&amp;rsquo;ll notice we&amp;rsquo;ve placed
four new lines in the previous empty second parameter. As described above,
these lines are what will be used in place of the keyword defined by the second
parameter. The actual lines in question are merely empty Autotest Macros, as
seen above. These must be used with values, as seen in the next section.&lt;/p&gt;

&lt;h3 id=&#34;the-test&#34;&gt;The test&lt;/h3&gt;

&lt;p&gt;The only test we&amp;rsquo;re writing here is for the following assertion:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;cat prints an error message for a non-existing file&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This test should just about do it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;m4_define([MYTEST_CHECK_CAT], [
  AT_BANNER([cat simple unit tests])
  AT_SETUP([execute cat with non-existing file])
  AT_CHECK([cat /dev/nulls], [ignore], [], [&amp;quot;cat: /dev/nulls: No such file or directory&amp;quot;])
  AT_CLEANUP
])

MYTEST_CHECK_CAT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each of the lines work as follow:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;AT_BANNER([cat simple unit tests])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This merely describes some test that should be printed before the tests are
executed. This is useful for providing a title to a group of tests and hence
enforcing separation between them.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;AT_SETUP([execute cat with non-existing file])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This describes the name of test in question. Most likely this is a brief
description of the test.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;AT_CHECK([cat /dev/nulls], [ignore], [], [&amp;quot;cat: /dev/nulls: No such file or directory&amp;quot;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is the real juicy part. The first parameter describes what operation to
run. In this case, we&amp;rsquo;re running cat on a non-existent file (note the &lt;code&gt;s&lt;/code&gt; in
&lt;code&gt;/dev/nulls&lt;/code&gt;). The second parameter describes the expected status. I&amp;rsquo;m not
entirely sure what the status could be, so I&amp;rsquo;ll ignore it. The third parameter
describes the stdout. This application should output to stderr rather than
stdout in the case of an error, so leave it empty. Finally the last parameter
describes the stderr. This is what the application should output on calling
this command and we ensure this is so.&lt;/p&gt;

&lt;h2 id=&#34;wrap-up&#34;&gt;Wrap up&lt;/h2&gt;

&lt;p&gt;It isn&amp;rsquo;t possible to run this test as-is, because we&amp;rsquo;re missing a lot of
configuration stuff (like the &lt;code&gt;AT_INIT&lt;/code&gt;). However, if you&amp;rsquo;re writing your own
tests, you&amp;rsquo;re most likely plugging into an existing test framework. The
specifics of this will change from project to project but someone on the
project&amp;rsquo;s team should be able to advise you on the specifics of integration.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Working with Jenkins &#43; Chrome</title>
      <link>https://that.guru/blog/helpful-jenkins-plugins/</link>
      <pubDate>Wed, 13 Jul 2016 14:46:56 +0100</pubDate>
      
      <guid>https://that.guru/blog/helpful-jenkins-plugins/</guid>
      <description>

&lt;p&gt;It&amp;rsquo;s been a while since I had to work with Jenkins directly (since I started on
OpenStack, really). However, I had a few tricks picked up around plugins for
Chrome that make working with pre-3.0 Jenkins a little more pleasant.&lt;/p&gt;

&lt;h1 id=&#34;buildreactor&#34;&gt;BuildReactor&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chrome.google.com/webstore/detail/buildreactor/agfdekbncfakhgofmaacjfkpbhjhpjmp&#34;&gt;Site&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/AdamNowotny/BuildReactor&#34;&gt;Source&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Overview&lt;/p&gt;

&lt;p&gt;This provides a current statuses of a user-defined number of Jenkins jobs.
It also gives notifications when projects pass/fail.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Installation&lt;/p&gt;

&lt;p&gt;Install from the Chrome store. Once installed, &amp;ldquo;Add&amp;rdquo; a new view, give it a
name (i.e. &amp;ldquo;Open vSwitch&amp;rdquo;) and configure the following settings:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Server: jenkins.example.com:8080
User:   [leave empty]
Pass:   [leave empty]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Substitute the appropriate URL for your local server. Once done, select the
&amp;ldquo;Show&amp;rdquo; button, and select which of the projects you want to display. Then
&amp;ldquo;Save&amp;rdquo;. You should now be able to get an overview of your builds by
clicking on the toolbar icon. You should also get notifications.  This is
easier to parse than the emails, IMO.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;doony&#34;&gt;Doony&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kevinburke/doony#chrome-extension&#34;&gt;Site&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kevinburke/doony&#34;&gt;Source&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Overview&lt;/p&gt;

&lt;p&gt;This provides a new, ultra-usable stylesheet for Jenkins. IMO it makes
Jenkins easier to work with.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Installation&lt;/p&gt;

&lt;p&gt;Follow the guide on the README. When modifying the &amp;lsquo;manifest.json&amp;rsquo; file,
add the following URLs:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;matches&amp;quot;: [
  &amp;quot;https://jenkins.ci.cloudbees.com/*&amp;quot;,
  &amp;quot;http://localhost:8080/*&amp;quot;,
  &amp;quot;https://jenkins.example.com:8080/*&amp;quot;,
  &amp;quot;http://jenkins.example.com:8080/*&amp;quot;,
  &amp;quot;https://jenkins.example.com/*&amp;quot;,
  &amp;quot;http://jenkins.example.com/*&amp;quot;,
],
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Substitute the appropriate URL for you local server. Don&amp;rsquo;t forget to
&amp;ldquo;reload&amp;rdquo; the plugin once installed.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>How are datacenters physically wired?</title>
      <link>https://that.guru/blog/how-are-datacenters-physically-wired/</link>
      <pubDate>Wed, 13 Jul 2016 14:33:21 +0100</pubDate>
      
      <guid>https://that.guru/blog/how-are-datacenters-physically-wired/</guid>
      <description>&lt;p&gt;I sent this question to my team in Intel some time ago.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I gave a run down on SDN, NFV and all things Open to the OpenStack new
hires today. One of the questions that came out of this concerned the
physical wiring of server room or datacenter using SDN. Does anyone
have any info on how n servers in a datacenter would be physically
connected (where n &amp;gt;= 100, for example)? In case it matters, I&amp;rsquo;m
picturing either a mesh network (high efficiency, high complexity) or
a hierarchical network of increasingly large-bandwidth switches and
routers (low efficiency, low complexity), but I&amp;rsquo;m only guessing here.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;https://ie.linkedin.com/in/robin-giller-1174193b&#34;&gt;Robin Giller&lt;/a&gt; started with an excellent introduction:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I believe that &amp;ldquo;leaf and spine&amp;rdquo; is the current topology of choice,
moving away from the &amp;ldquo;fat tree&amp;rdquo; architecture of the past when one
inbound request needed to be routed to one server, who would compute
and send data back up to the core and out. Leaf and spine is more
efficient when you&amp;rsquo;ve got lots of east-west traffic. There&amp;rsquo;s an
explanation of both in the link below, and loads more available - just search
for leaf and spine.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://searchdatacenter.techtarget.com/feature/Data-center-network-design-moves-from-tree-to-leaf&#34;&gt;http://searchdatacenter.techtarget.com/feature/Data-center-network-design-moves-from-tree-to-leaf&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;While the always helpful &lt;a href=&#34;https:/ie.linkedin.com/in/sean-mooney-7a842429&#34;&gt;Sean Mooney&lt;/a&gt; provided that little bit
of additional info:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;To expand on that, I believe it is leaf spine at the pod level (~5-10 racks
of servers) with spine switches interconnected in a mesh.&lt;/p&gt;

&lt;p&gt;So each spine switch will be connected to leaf top-of-rack switches and then
interconnected with other spine switches to form a core mesh network.&lt;/p&gt;

&lt;p&gt;There is also work in OpenStack around Hierarchical Port Binding to allow
different overlay technologies to be used at the spine and leaf layers.
&lt;a href=&#34;https://blueprints.launchpad.net/neutron/+spec/ml2-hierarchical-port-binding&#34;&gt;https://blueprints.launchpad.net/neutron/+spec/ml2-hierarchical-port-binding&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;With Hierarchical Port Binding you can use vlans between server and leaf
level and vxlan or other more scalable/computationally expensive overlays at
the leaf/spine level.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Interesting stuff.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Loading mailing list archives with Mutt</title>
      <link>https://that.guru/blog/mutt-archives/</link>
      <pubDate>Wed, 13 Jul 2016 10:59:30 +0100</pubDate>
      
      <guid>https://that.guru/blog/mutt-archives/</guid>
      <description>&lt;p&gt;You can use &lt;a href=&#34;http://www.mutt.org/&#34;&gt;Mutt&lt;/a&gt; to load archives from a mailing list. This is useful
for replying to mails when you weren&amp;rsquo;t previously subscribed to said mailing
list.&lt;/p&gt;

&lt;p&gt;To begin, first go to the archive site for your given mailing list. This will
probably be a Pipermail instance. Once here, identify the archives you require:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/mutt-archives-1.png&#34; alt=&#34;Screenshot of the download button for Pipermail&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Download the archive&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;Once you&amp;rsquo;ve identified this, download and, if necessary, extract the archive:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget http://openvswitch.org/pipermail/dev/2016-June.txt.gz
$ gunzip 2016-June.txt.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This extracted archive file will be in mbox format, and can be easily loaded
with mutt:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mutt -f 2016-June.txt
&lt;/code&gt;&lt;/pre&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/mutt-archives-2.png&#34; alt=&#34;Screenshot of Mutt with archives loaded&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;All patches available in Mutt&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;

</description>
    </item>
    
    <item>
      <title>Sane Outlook: Making plain text better in Outlook</title>
      <link>https://that.guru/blog/sane-outlook/</link>
      <pubDate>Mon, 11 Jul 2016 18:11:38 +0100</pubDate>
      
      <guid>https://that.guru/blog/sane-outlook/</guid>
      <description>

&lt;p&gt;I like well-formatted, plain text emails, and I like reading them in a
monospace font. I find plain text to be more readable, and provides less ways
for people to impact this legibility. Sadly, Outlooks defaults to settings that
seemingly encourage bad email ettiquete. Fortunately, we can wrangle Outlook
into working some bit normally. You still need to do a bit of work (removing
the Outlook context header, giving out to people for top-posting (☺), etc.),
but it&amp;rsquo;s better.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/sane-outlook-1.png&#34; alt=&#34;Screenshot of plain text mail before changes&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;A plain text email before&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/sane-outlook-2.png&#34; alt=&#34;Screenshot of plain text mail after changes&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;...and after&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;h2 id=&#34;send-new-emails-using-plain-text&#34;&gt;Send new emails using plain text&lt;/h2&gt;

&lt;p&gt;The first step on our road to plain text greatness is to always send new emails
using plain text. This won&amp;rsquo;t modify the formatting of replies: only new emails
from you.&lt;/p&gt;

&lt;p&gt;You can do this in settings menu (Alt + F, Alt + T). Once here, click on the
mail tab and change the &amp;ldquo;Compose messages in this format:&amp;rdquo; option.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/sane-outlook-3.png&#34; alt=&#34;Screenshot of configuring Outlook to send new emails in plain text&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Send new messages in plain text&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;h2 id=&#34;prefix-and-wrap-replies-correctly&#34;&gt;Prefix and wrap replies correctly&lt;/h2&gt;

&lt;p&gt;Next up, let&amp;rsquo;s prefix our emails with the &amp;lsquo;&amp;gt; &amp;rsquo; character. Scroll down on the
same settings dialog and enable this.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/sane-outlook-4.png&#34; alt=&#34;Screenshot of configuring Outlook to prefix replies in a plain text email&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Prefix replies to plain text emails&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;We should also disable stripping of extra line breaks and force wrapping of the
message. For the latter, note that this wrapping is done using Windows&amp;rsquo; CRLF
combination, thus, users of non-Windows clients may see an extra newline
between each line. This isn&amp;rsquo;t configurable, sadly.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/sane-outlook-5.png&#34; alt=&#34;Screenshot of configuring Outlook to not strip extra line breaks&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Don&amp;#39;t strip extra line breaks&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;h2 id=&#34;display-emails-in-monospace-font&#34;&gt;Display emails in monospace font&lt;/h2&gt;

&lt;p&gt;The final step of this is display the emails in a nice, monospace font. I have
&lt;a href=&#34;https://adobe-fonts.github.io/source-code-pro/&#34;&gt;Source Code Pro&lt;/a&gt; installed, and use the &amp;ldquo;Light&amp;rdquo; variant of this in
Outlook. To do this, select the &amp;ldquo;&lt;em&gt;Stationary and Fonts&amp;hellip;&lt;/em&gt;&amp;rdquo; button in that same
pane.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/sane-outlook-6.png&#34; alt=&#34;Screenshot of configuring Outlook to use monospace font (1)&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Open the Stationary and Fonts dialog&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;Once here, modify the config for &amp;ldquo;&lt;em&gt;Composing and reading plain text messages&lt;/em&gt;&amp;rdquo;.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/sane-outlook-7.png&#34; alt=&#34;Screenshot of configuring Outlook to use monospace font (2)&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;We&amp;#39;re changing plain text message formating&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;Finally, set your desired monospace font.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/sane-outlook-8.png&#34; alt=&#34;Screenshot of configuring Outlook to use monospace font (3)&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Open the Stationary and Fonts dialog&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;h2 id=&#34;wrap-up&#34;&gt;Wrap Up&lt;/h2&gt;

&lt;p&gt;Better plain text emails, for the win.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/sane-outlook-9.png&#34; alt=&#34;Screenshot of plain text email with correctly configured Outlook&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Beautiful, monospace messages&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;

</description>
    </item>
    
    <item>
      <title>How I Work</title>
      <link>https://that.guru/blog/how-i-work/</link>
      <pubDate>Sat, 09 Jul 2016 18:08:16 +0100</pubDate>
      
      <guid>https://that.guru/blog/how-i-work/</guid>
      <description>

&lt;p&gt;Next Friday is the last week of this stint at Intel, so I figured now was as
good a time as ever to do a write up on how I work, or, more accurately, how
I&amp;rsquo;ve worked, during my time here. Note that this has evolved massively over the
past three years, so expect what I say now to have changed significantly a year
down the line.&lt;/p&gt;

&lt;p&gt;At the moment, I work predominantly on &lt;a href=&#34;https://github.com/openstack/nova&#34;&gt;nova&lt;/a&gt;, though I contribute to
many other projects like &lt;a href=&#34;https://github.com/openstack/openstack-manuals&#34;&gt;openstack-manuals&lt;/a&gt;,
&lt;a href=&#34;https://github.com/openstack/oslo.config&#34;&gt;oslo.config&lt;/a&gt;, &lt;a href=&#34;https://github.com/openstack-dev/devstack&#34;&gt;DevStack&lt;/a&gt; and &lt;a href=&#34;https://github.com/getpatchwork/patchwork&#34;&gt;Patchwork&lt;/a&gt;.
Not all of these projects are OpenStack projects, but they are all
Python-based, meaning the development environments for each tend to be rather
similar.&lt;/p&gt;

&lt;h2 id=&#34;platform&#34;&gt;Platform&lt;/h2&gt;

&lt;p&gt;First up - my development platform. My current work laptop is a tad
bit&amp;hellip;under-resourced (think: 4GB of RAM) and is Windows-based, meaning I
always end up working on remote machines via SSH (more on that later). The
remote machines I use vary depending on what I want to do. Most of the time I
use a handful of VMs provided via an internal cloud. These provide me with a
shared home directory (so I don&amp;rsquo;t have to configure Vim each time I start using
a new VM, heh) and some flexibility for things like basic multi-node testing.
However, when I need to validate features on real hardware (which happens quite
regularly, given the areas I&amp;rsquo;m working on), I&amp;rsquo;ll use some real hardware from
the lab. These platforms are the kind of platforms you&amp;rsquo;ll find in every good
data center around the world: multiple top-of-the-line Xeon E5s, super-fast
NVMe SSD storage, the latest Intel NICs (SR-IOV compatible, of course) and
many, many GBs of RAM.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/how-i-work-1.png&#34; alt=&#34;Screenshot showing output of /proc/meminfo&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;That&amp;#39;s a lot of RAM&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/how-i-work-2.png&#34; alt=&#34;Screenshot showing output of /proc/cpuinfo&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;One of many cores&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;h2 id=&#34;environment&#34;&gt;Environment&lt;/h2&gt;

&lt;p&gt;While the hardware of the platforms I use does vary tremendously, the software
environments are remarkably consistent. To start, everything runs whatever the
latest version of Fedora happens to be - while Ubuntu may be currently &lt;a href=&#34;https://www.openstack.org/assets/survey/April-2016-User-Survey-Report.pdf&#34;&gt;the
most popular platform to deploy OpenStack on&lt;/a&gt;, I&amp;rsquo;ve used
Fedora at home for years and saw no reason to switch. On top of this, I either
deploy OpenStack using DevStack, if I want to validate a feature, or I simply
clone and work on the project repos directly, if I&amp;rsquo;m working or unit-testable
code or &amp;ldquo;low-hanging-fruit&amp;rdquo; tasks. Finally, where required, I pre-configure my
tools using the configuration files provided by my &lt;a href=&#34;https://github.com/stephenfin/dotfiles&#34;&gt;dotfiles&lt;/a&gt;
project.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/how-i-work-3.png&#34; alt=&#34;Screenshot showing OpenStack projects I&amp;#39;ve worked on&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;I work on a lot of projects&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;h2 id=&#34;tooling&#34;&gt;Tooling&lt;/h2&gt;

&lt;p&gt;Tooling makes or breaks developers: learning what tools to use, and when, is an
important part of any developers own development. I know a lot of people who
use IDEs like &lt;a href=&#34;https://www.jetbrains.com/pycharm/&#34;&gt;PyCharm&lt;/a&gt; (indeed, you can get a &lt;a href=&#34;https://wiki.openstack.org/wiki/How_To_Contribute#If_you.27re_a_developer&#34;&gt;free community
license&lt;/a&gt; if you contribute to OpenStack), but seeing as I don&amp;rsquo;t
develop on my local machine, I need to use some form of remote rendering - VNC,
X11 forwarding, RDP - for the IDE GUI, I need to configure a remote mount so
that a local installed IDE could access files on my remote machines. I&amp;rsquo;ve found
both of these options to perform poorly over bad connections and result in
either a janky, laggy UI or an inability to do things like change branches with
any regularity, respectively. Annoying, to say the least.&lt;/p&gt;

&lt;p&gt;As a result of the above, I&amp;rsquo;ve been slowly dropping GUI-based tools from my
toolkit over the years. The largest change here was my replacment of Sublime
Text and its plugins with Vim and plugins managed by &lt;a href=&#34;https://github.com/VundleVim/Vundle.vim&#34;&gt;Vundle&lt;/a&gt;
(delighted not to be writing plugins for Vim, tbh). In addition to this change,
I also dropped [Meld], which was pretty but laggy over X11 forwarding, in favor
of the more responsive &lt;a href=&#34;https://github.com/rhysd/conflict-marker.vim&#34;&gt;ConflictMarker&lt;/a&gt; Vim plugin (I&amp;rsquo;m yet to
grasp Vimdiff).  Similarly, I&amp;rsquo;ve replaced MTPuTTY and its multiple tabs with
standard PuTTY and &lt;a href=&#34;https://tmux.github.io/&#34;&gt;tmux&lt;/a&gt;. All these tools do have an additional learning
curve over their GUI-driven equivalents, but they&amp;rsquo;re all battle-tested,
incredibly efficient, and work well on pretty much any type of network
connection.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/how-i-work-4.png&#34; alt=&#34;Screenshot of Vim in tmux&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;I use Vim extensively&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;Outside of these tools, I also make extensive use of &lt;a href=&#34;https://github.com/openstack-infra/git-review&#34;&gt;git-review&lt;/a&gt;
and &lt;a href=&#34;https://github.com/ggreer/the_silver_searcher&#34;&gt;ag (a.k.a. the silver searcher)&lt;/a&gt;. git-review allows me to quickly
submit my own changes for community review or download other peoples&amp;rsquo; changes
for validation, and it is the tool the OpenStack community recommends for
working with Gerrit-based projects. ag, on the other hand, is my way of
handling the lack of an IntelliSense-like feature in Vim. It&amp;rsquo;s a faster version
of &lt;code&gt;awk&lt;/code&gt; that also takes things like gitignore files into account. I use this
to search for function calls etc. I plan to eventually try something like
&lt;a href=&#34;https://github.com/davidhalter/jedi&#34;&gt;Jedi&lt;/a&gt; but I just haven&amp;rsquo;t got around to this yet.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/how-i-work-5.png&#34; alt=&#34;Screenshot of ag in tmux&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;ag is fast and pretty&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;Finally, debugging, where necessary, is possible through &lt;a href=&#34;https://docs.python.org/2/library/pdb.html&#34;&gt;pdb&lt;/a&gt; and the odd
post to the mailing list is made using &lt;a href=&#34;http://www.mutt.org/&#34;&gt;mutt&lt;/a&gt;. pdb, like many of these
tools, does take a bit of time to get your head around, but, once up and
running, proves itself worth the effort. mutt has a similarly large learning
curve, but it doesn&amp;rsquo;t mess up the formatting of emails half as bad as Outlook
and its threading actually works.&lt;/p&gt;

&lt;h2 id=&#34;future-plans&#34;&gt;Future Plans&lt;/h2&gt;

&lt;p&gt;There are a couple of tools that have been recommended to me, that I just
haven&amp;rsquo;t got around to trying yet.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dolph/next-review&#34;&gt;git-next&lt;/a&gt;: Developed by the awesome Dolph Matthews, this simple
tool should be configured with your favourite OpenStack project. Once done, you
can run it provide you with the next patch that you should review.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/openstack/gertty&#34;&gt;gertty&lt;/a&gt;: This is another OpenStack-provided project. This tool
provides a CLI for Gerrit tool, and allows you to do things like review code
offline. The latter feature isn&amp;rsquo;t so useful when working remotely all the time,
but if/when I start developing locally, I&amp;rsquo;ll be sure to use this.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/davidhalter/jedi&#34;&gt;Jedi&lt;/a&gt;: As mentioned above, how I navigate the code base could do with
a bit of work. Jedi brings autocomplete and some other stuff to editors like
Vim.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jetbrains.com/pycharm/&#34;&gt;PyCharm&lt;/a&gt;: This is another one to throw in the &amp;ldquo;if I ever develop
locally&amp;rdquo; bag. I don&amp;rsquo;t use this now, but if it becomes an option then I&amp;rsquo;ll
definitely try it. I do wish the open source alternatives weren&amp;rsquo;t quite
so&amp;hellip;Java&amp;rsquo;y though.&lt;/li&gt;
&lt;li&gt;???: Who knows what else I&amp;rsquo;ll discover in the coming years?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;bonus-ssh-configuration&#34;&gt;Bonus: SSH Configuration&lt;/h2&gt;

&lt;p&gt;How I actually connect to the machines is probably worth calling out also. For
this, I use the PuTTY family of tools. To begin with, I have
&lt;a href=&#34;https://github.com/FauxFaux/PuTTYTray&#34;&gt;PuTTYTray&lt;/a&gt; installed and pinned to my taskbar to enable quick
access to some tools in the suite (&lt;a href=&#34;http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html&#34;&gt;PuTTY, Pageant, PuTTYGen&lt;/a&gt;).&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/how-i-work-6.png&#34; alt=&#34;Screenshot of PuTTYTray&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;PuTTYTray in action&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;The out-of-the-box experience for PuTTY itself is rather poor, so I rely on the
&lt;a href=&#34;https://github.com/jblaine/solarized-and-modern-putty&#34;&gt;Solarized Modern PuTTY Defaults project&lt;/a&gt; to bring things into the
21st century.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/how-i-work-7.png&#34; alt=&#34;Screenshot of PuTTY&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Pretty colours. Not so pretty test results.&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;I don&amp;rsquo;t fancy typing in a password each time, so I &lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-use-ssh-keys-with-putty-on-digitalocean-droplets-windows-users&#34;&gt;generate SSH keys using
Pageant&lt;/a&gt;, then I make sure Pageant &lt;a href=&#34;http://blog.shvetsov.com/2010/03/making-pageant-automatically-load-keys.html&#34;&gt;starts automatically&lt;/a&gt;
each time I boot my machine. I&amp;rsquo;ll probably do a more in-depth write up of this
process at some point.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Resizing pinned instances to unpinned</title>
      <link>https://that.guru/blog/resizing-pinned-to-unpinned/</link>
      <pubDate>Thu, 30 Jun 2016 10:55:58 +0100</pubDate>
      
      <guid>https://that.guru/blog/resizing-pinned-to-unpinned/</guid>
      <description>

&lt;p&gt;OpenStack Nova provides support for &lt;a href=&#34;http://docs.openstack.org/user-guide/cli_change_the_size_of_your_server.html&#34;&gt;resize operations&lt;/a&gt;, or the
changing of the &lt;a href=&#34;http://docs.openstack.org/admin-guide/compute-flavors.html&#34;&gt;flavor&lt;/a&gt; associated with instance. This allows you to
add or remove resources from the instance, in addition to modifying other
configuration associated with the flavor.&lt;/p&gt;

&lt;p&gt;There were reports that resizing an instance from a &lt;a href=&#34;http://docs.openstack.org/admin-guide/compute-numa-cpu-pinning.html&#34;&gt;pinned
flavor&lt;/a&gt; to a unpinned one did not result in the pinning being
removed. The opposite was also reportedly true. I investigated this to see if
this was the case.&lt;/p&gt;

&lt;h1 id=&#34;steps&#34;&gt;Steps&lt;/h1&gt;

&lt;h2 id=&#34;create-the-required-flavors&#34;&gt;Create the required flavors&lt;/h2&gt;

&lt;p&gt;The first step we&amp;rsquo;ll do is create two new flavors - &lt;code&gt;test.unpinned&lt;/code&gt; and
&lt;code&gt;test.pinned&lt;/code&gt;. Begin by creating these:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openstack flavor create test.unpinned \
  --id 100 --ram 2048 --disk 0 --vcpus 2
$ openstack flavor create test.pinned \
  --id 101 --ram 2048 --disk 0 --vcpus 2
$ openstack flavor set test.pinned --property &amp;quot;hw:cpu_policy=dedicated&amp;quot;

$ openstack flavor list
+-----+---------------+-------+------+-----------+-------+-----------+
| ID  | Name          |   RAM | Disk | Ephemeral | VCPUs | Is Public |
+-----+---------------+-------+------+-----------+-------+-----------+
| 1   | m1.tiny       |   512 |    1 |         0 |     1 | True      |
| 101 | test.unpinned |  2048 |    0 |         0 |     2 | True      |
| 101 | test.pinned   |  2048 |    0 |         0 |     2 | True      |
| 2   | m1.small      |  2048 |   20 |         0 |     1 | True      |
| 3   | m1.medium     |  4096 |   40 |         0 |     2 | True      |
| 4   | m1.large      |  8192 |   80 |         0 |     4 | True      |
| 42  | m1.nano       |    64 |    0 |         0 |     1 | True      |
| 5   | m1.xlarge     | 16384 |  160 |         0 |     8 | True      |
| 84  | m1.micro      |   128 |    0 |         0 |     1 | True      |
+-----+---------------+-------+------+-----------+-------+-----------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;create-a-new-instance&#34;&gt;Create a new instance&lt;/h2&gt;

&lt;p&gt;Now create the new instance, based on the &lt;code&gt;test.pinned&lt;/code&gt; flavor:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openstack image list
+--------------------------------------+---------------------------------+--------+
| ID                                   | Name                            | Status |
+--------------------------------------+---------------------------------+--------+
| c44bba29-653e-4ddf-963d-442af4c33a13 | cirros-0.3.4-x86_64-uec         | active |
| 8b0284ee-ae6c-4e80-b5ee-26895d574717 | cirros-0.3.4-x86_64-uec-ramdisk | active |
| 855c2971-aedc-4d5f-a366-73bb14707965 | cirros-0.3.4-x86_64-uec-kernel  | active |
+--------------------------------------+---------------------------------+--------+

$ openstack server create --flavor=test.pinned \
  --image=cirros-0.3.4-x86_64-uec --wait test1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;validate-that-the-instance-is-pinned&#34;&gt;Validate that the instance is pinned&lt;/h2&gt;

&lt;p&gt;Ensure the instance is actually pinned in the first place before we resize
anything:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openstack server list
+--------------------------------------+-------+--------+--------------------------------------------------------+
| ID                                   | Name  | Status | Networks                                               |
+--------------------------------------+-------+--------+--------------------------------------------------------+
| 857597cb-266b-4032-8030-e3cc76ebf0e7 | test1 | ACTIVE | private=10.0.0.3, fd2a:ec16:99e1:0:f816:3eff:fe99:df9f |
+--------------------------------------+-------+--------+--------------------------------------------------------+

$ sudo virsh list
 Id    Name                           State
----------------------------------------------------
 1     instance-00000001              running

$ sudo virsh dumpxml instance-00000001
&amp;lt;domain type=&#39;kvm&#39; id=&#39;1&#39;&amp;gt;
  &amp;lt;name&amp;gt;instance-00000001&amp;lt;/name&amp;gt;
  ...
  &amp;lt;vcpu placement=&#39;static&#39;&amp;gt;2&amp;lt;/vcpu&amp;gt;
  &amp;lt;cputune&amp;gt;
    &amp;lt;shares&amp;gt;2048&amp;lt;/shares&amp;gt;
    &amp;lt;vcpupin vcpu=&#39;0&#39; cpuset=&#39;1&#39;/&amp;gt;
    &amp;lt;vcpupin vcpu=&#39;1&#39; cpuset=&#39;21&#39;/&amp;gt;
    &amp;lt;emulatorpin cpuset=&#39;1,21&#39;/&amp;gt;
  &amp;lt;/cputune&amp;gt;
  &amp;lt;numatune&amp;gt;
    &amp;lt;memory mode=&#39;strict&#39; nodeset=&#39;0&#39;/&amp;gt;
    &amp;lt;memnode cellid=&#39;0&#39; mode=&#39;strict&#39; nodeset=&#39;0&#39;/&amp;gt;
  &amp;lt;/numatune&amp;gt;
  ...
  &amp;lt;cpu&amp;gt;
    &amp;lt;topology sockets=&#39;1&#39; cores=&#39;1&#39; threads=&#39;2&#39;/&amp;gt;
    &amp;lt;numa&amp;gt;
      &amp;lt;cell id=&#39;0&#39; cpus=&#39;0-1&#39; memory=&#39;2097152&#39; unit=&#39;KiB&#39;/&amp;gt;
    &amp;lt;/numa&amp;gt;
  &amp;lt;/cpu&amp;gt;
  ...
&amp;lt;/domain&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;resize-the-instance-to-the-unpinned-flavor&#34;&gt;Resize the instance to the unpinned flavor&lt;/h2&gt;

&lt;p&gt;Seeing as pinning was in effect, we can now resize to the &lt;code&gt;test.unpinned&lt;/code&gt;
flavor:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openstack server resize test1 --flavor test.unpinned --wait
complete

$ openstack server list
+--------------------------------------+-------+---------------+--------------------------------------------------------+
| ID                                   | Name  | Status        | Networks                                               |
+--------------------------------------+-------+---------------+--------------------------------------------------------+
| 857597cb-266b-4032-8030-e3cc76ebf0e7 | test1 | VERIFY_RESIZE | private=10.0.0.3, fd2a:ec16:99e1:0:f816:3eff:fe99:df9f |
+--------------------------------------+-------+---------------+--------------------------------------------------------+

$ openstack server resize test1 --confirm
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;validate-that-the-instance-is-no-longer-pinned&#34;&gt;Validate that the instance is no longer pinned&lt;/h2&gt;

&lt;p&gt;Once resized, check to see if the instance has been unpinned:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openstack server list
+--------------------------------------+-------+--------+--------------------------------------------------------+
| ID                                   | Name  | Status | Networks                                               |
+--------------------------------------+-------+--------+--------------------------------------------------------+
| 857597cb-266b-4032-8030-e3cc76ebf0e7 | test1 | ACTIVE | private=10.0.0.3, fd2a:ec16:99e1:0:f816:3eff:fe99:df9f |
+--------------------------------------+-------+--------+--------------------------------------------------------+

$ sudo virsh list
 Id    Name                           State
----------------------------------------------------
 2     instance-00000001              running

$ sudo virsh dumpxml instance-00000001
&amp;lt;domain type=&#39;kvm&#39; id=&#39;2&#39;&amp;gt;
  &amp;lt;name&amp;gt;instance-00000002&amp;lt;/name&amp;gt;
  ...
  &amp;lt;vcpu placement=&#39;static&#39;&amp;gt;2&amp;lt;/vcpu&amp;gt;
  &amp;lt;cputune&amp;gt;
    &amp;lt;shares&amp;gt;2048&amp;lt;/shares&amp;gt;
  &amp;lt;/cputune&amp;gt;
  ...
&amp;lt;/domain&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;resize-the-instance-back-to-the-pinned-flavor&#34;&gt;Resize the instance back to the pinned flavor&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s go back the other way, and resize back to the &lt;code&gt;test.pinned&lt;/code&gt; flavor:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openstack server resize test1 --flavor test.pinned --wait
complete

$ openstack server list
+--------------------------------------+-------+---------------+--------------------------------------------------------+
| ID                                   | Name  | Status        | Networks                                               |
+--------------------------------------+-------+---------------+--------------------------------------------------------+
| 857597cb-266b-4032-8030-e3cc76ebf0e7 | test1 | VERIFY_RESIZE | private=10.0.0.3, fd2a:ec16:99e1:0:f816:3eff:fe99:df9f |
+--------------------------------------+-------+---------------+--------------------------------------------------------+

$ openstack server resize test1 --confirm
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;validate-that-the-instance-is-pinned-once-more&#34;&gt;Validate that the instance is pinned once more&lt;/h2&gt;

&lt;p&gt;Finally, ensure the instance is once again pinned:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openstack server list
+--------------------------------------+-------+--------+--------------------------------------------------------+
| ID                                   | Name  | Status | Networks                                               |
+--------------------------------------+-------+--------+--------------------------------------------------------+
| 857597cb-266b-4032-8030-e3cc76ebf0e7 | test1 | ACTIVE | private=10.0.0.3, fd2a:ec16:99e1:0:f816:3eff:fe99:df9f |
+--------------------------------------+-------+--------+--------------------------------------------------------+

$ sudo virsh list
 Id    Name                           State
----------------------------------------------------
 3     instance-00000001              running

$ sudo virsh dumpxml instance-00000001
&amp;lt;domain type=&#39;kvm&#39; id=&#39;3&#39;&amp;gt;
  &amp;lt;name&amp;gt;instance-00000001&amp;lt;/name&amp;gt;
  ...
  &amp;lt;vcpu placement=&#39;static&#39;&amp;gt;2&amp;lt;/vcpu&amp;gt;
  &amp;lt;cputune&amp;gt;
    &amp;lt;shares&amp;gt;2048&amp;lt;/shares&amp;gt;
    &amp;lt;vcpupin vcpu=&#39;0&#39; cpuset=&#39;1&#39;/&amp;gt;
    &amp;lt;vcpupin vcpu=&#39;1&#39; cpuset=&#39;21&#39;/&amp;gt;
    &amp;lt;emulatorpin cpuset=&#39;1,21&#39;/&amp;gt;
  &amp;lt;/cputune&amp;gt;
  &amp;lt;numatune&amp;gt;
    &amp;lt;memory mode=&#39;strict&#39; nodeset=&#39;0&#39;/&amp;gt;
    &amp;lt;memnode cellid=&#39;0&#39; mode=&#39;strict&#39; nodeset=&#39;0&#39;/&amp;gt;
  &amp;lt;/numatune&amp;gt;
  ...
  &amp;lt;cpu&amp;gt;
    &amp;lt;topology sockets=&#39;1&#39; cores=&#39;1&#39; threads=&#39;2&#39;/&amp;gt;
    &amp;lt;numa&amp;gt;
      &amp;lt;cell id=&#39;0&#39; cpus=&#39;0-1&#39; memory=&#39;2097152&#39; unit=&#39;KiB&#39;/&amp;gt;
    &amp;lt;/numa&amp;gt;
  &amp;lt;/cpu&amp;gt;
  ...
&amp;lt;/domain&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;result&#34;&gt;Result&lt;/h1&gt;

&lt;p&gt;It is possible to resize from pinned to unpinned, and from unpinned to pinned.
No issues here.&lt;/p&gt;

&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.openstack.org/admin-guide/compute-flavors.html&#34;&gt;OpenStack Administrator Guide: Compute flavors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.openstack.org/admin-guide/compute-numa-cpu-pinning.html&#34;&gt;OpenStack Administrator Guide: Enabling advanced CPU topologies in
guests&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>CPU pinning with image metadata</title>
      <link>https://that.guru/blog/cpu-pinning-with-image-metadata/</link>
      <pubDate>Wed, 29 Jun 2016 17:52:20 +0100</pubDate>
      
      <guid>https://that.guru/blog/cpu-pinning-with-image-metadata/</guid>
      <description>

&lt;p&gt;OpenStack Nova allows the specification of &lt;a href=&#34;http://docs.openstack.org/image-guide/image-metadata.html&#34;&gt;image metadata&lt;/a&gt; to
provide per-instance metadata. This is similar to the &lt;a href=&#34;http://docs.openstack.org/admin-guide/compute-flavors.html&#34;&gt;flavor&lt;/a&gt; &lt;a href=&#34;http://docs.openstack.org/admin-guide/compute-flavors.html#extra-specs&#34;&gt;extra
specs&lt;/a&gt;. The CPU pinning feature makes use of this to allow for
configuration of CPU policies and CPU thread policies via such metdata.&lt;/p&gt;

&lt;p&gt;Someone suggested to me that CPU policies many not be being applied correctly
when stored as image metadata rather than flavor properties. I decided to
investigate this claim.&lt;/p&gt;

&lt;p&gt;Commit &lt;a href=&#34;https://github.com/openstack/nova/tree/8bafc9&#34;&gt;&lt;code&gt;8bafc9&lt;/code&gt;&lt;/a&gt; of Nova was used for this testing. Much of
this feature has been &lt;a href=&#34;http://docs.openstack.org/admin-guide/compute-numa-cpu-pinning.html&#34;&gt;documented upstreamed&lt;/a&gt; since conducting
this testing.&lt;/p&gt;

&lt;h1 id=&#34;steps&#34;&gt;Steps&lt;/h1&gt;

&lt;h2 id=&#34;create-a-custom-image-with-metadata&#34;&gt;Create a custom image with metadata&lt;/h2&gt;

&lt;p&gt;The first step is to create a new image and save metadata against this image.
To do this, we&amp;rsquo;ll duplicate an existing image and modify this duplicate. Begin
by duplicating the image:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openstack image list
+--------------------------------------+---------------------------------+--------+
| ID                                   | Name                            | Status |
+--------------------------------------+---------------------------------+--------+
| a3450a21-f012-4807-a514-0838750d430e | cirros-0.3.4-x86_64-uec         | active |
| 742bc914-e60c-4eab-9e5b-0a1c19ec1a84 | cirros-0.3.4-x86_64-uec-ramdisk | active |
| 3e507ab7-080d-4eea-845a-69950ec139b8 | cirros-0.3.4-x86_64-uec-kernel  | active |
+--------------------------------------+---------------------------------+--------+

$ openstack image save --file cirros.img a3450a21-f012-4807-a514-0838750d430e

$ openstack image create --file cirros.img cirros-0.3.4-x86_64-pinned
+------------------+------------------------------------------------------+
| Field            | Value                                                |
+------------------+------------------------------------------------------+
| checksum         | eb9139e4942121f22bbc2afc0400b2a4                     |
| container_format | bare                                                 |
| created_at       | 2016-02-16T09:40:12Z                                 |
| disk_format      | raw                                                  |
| file             | /v2/images/e3e7d5a5-b044-493a-b3e1-fa9ba6225ed6/file |
| id               | e3e7d5a5-b044-493a-b3e1-fa9ba6225ed6                 |
| min_disk         | 0                                                    |
| min_ram          | 0                                                    |
| name             | cirros-0.3.4-x86_64-pinned                           |
| owner            | c1e8c7671b0f4016a9250a8787de6930                     |
| protected        | False                                                |
| schema           | /v2/schemas/image                                    |
| size             | 25165824                                             |
| status           | active                                               |
| tags             |                                                      |
| updated_at       | 2016-02-16T09:40:12Z                                 |
| virtual_size     | None                                                 |
| visibility       | private                                              |
+------------------+------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next up, add the metadata to the image. We&amp;rsquo;ll only worry about CPU pinning, by
way of CPU policies, ignoring CPU thread pinning for now.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openstack image set cirros-0.3.4-x86_64-pinned --property hw_cpu_policy=dedicated

$ openstack image list
+--------------------------------------+---------------------------------+--------+
| ID                                   | Name                            | Status |
+--------------------------------------+---------------------------------+--------+
| e3e7d5a5-b044-493a-b3e1-fa9ba6225ed6 | cirros-0.3.4-x86_64-pinned      | active |
| a3450a21-f012-4807-a514-0838750d430e | cirros-0.3.4-x86_64-uec         | active |
| 742bc914-e60c-4eab-9e5b-0a1c19ec1a84 | cirros-0.3.4-x86_64-uec-ramdisk | active |
| 3e507ab7-080d-4eea-845a-69950ec139b8 | cirros-0.3.4-x86_64-uec-kernel  | active |
+--------------------------------------+---------------------------------+--------+

$ openstack image show cirros-0.3.4-x86_64-pinned
+------------------+------------------------------------------------------+
| Field            | Value                                                |
+------------------+------------------------------------------------------+
| checksum         | eb9139e4942121f22bbc2afc0400b2a4                     |
| container_format | bare                                                 |
| created_at       | 2016-02-16T09:40:12Z                                 |
| disk_format      | raw                                                  |
| file             | /v2/images/e3e7d5a5-b044-493a-b3e1-fa9ba6225ed6/file |
| id               | e3e7d5a5-b044-493a-b3e1-fa9ba6225ed6                 |
| min_disk         | 0                                                    |
| min_ram          | 0                                                    |
| name             | cirros-0.3.4-x86_64-pinned                           |
| owner            | c1e8c7671b0f4016a9250a8787de6930                     |
| properties       | hw_cpu_policy=&#39;dedicated&#39;                            |
| protected        | False                                                |
| schema           | /v2/schemas/image                                    |
| size             | 25165824                                             |
| status           | active                                               |
| tags             |                                                      |
| updated_at       | 2016-02-16T09:41:42Z                                 |
| virtual_size     | None                                                 |
| visibility       | private                                              |
+------------------+------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;create-a-new-instance&#34;&gt;Create a new instance&lt;/h2&gt;

&lt;p&gt;Now create the flavor. There&amp;rsquo;s no need to specify any metadata on the flavors:
it&amp;rsquo;s already specified in the image:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openstack flavor list
+----+-----------+-------+------+-----------+-------+-----------+
| ID | Name      |   RAM | Disk | Ephemeral | VCPUs | Is Public |
+----+-----------+-------+------+-----------+-------+-----------+
| 1  | m1.tiny   |   512 |    1 |         0 |     1 | True      |
| 2  | m1.small  |  2048 |   20 |         0 |     1 | True      |
| 3  | m1.medium |  4096 |   40 |         0 |     2 | True      |
| 4  | m1.large  |  8192 |   80 |         0 |     4 | True      |
| 42 | m1.nano   |    64 |    0 |         0 |     1 | True      |
| 5  | m1.xlarge | 16384 |  160 |         0 |     8 | True      |
| 84 | m1.micro  |   128 |    0 |         0 |     1 | True      |
+----+-----------+-------+------+-----------+-------+-----------+

$ openstack server create --flavor=m1.small --image=cirros-0.3.4-x86_64-pinned --wait test1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;validate-that-the-instance-has-been-created&#34;&gt;Validate that the instance has been created&lt;/h2&gt;

&lt;p&gt;Finally, ensure that things behave as expected. Instances should define an NUMA
topology and CPU pinning in the libvirt XML file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openstack server list
+--------------------------------------+-------+--------+--------------------------------------------------------+
| ID                                   | Name  | Status | Networks                                               |
+--------------------------------------+-------+--------+--------------------------------------------------------+
| 22c1afeb-06d8-4f6d-a8d8-7ea40ea9ff47 | test1 | ACTIVE | private=fd4d:adb9:5ebe:0:f816:3eff:fecd:a674, 10.0.0.3 |
+--------------------------------------+-------+--------+--------------------------------------------------------+

$ sudo virsh list
 Id    Name                           State
----------------------------------------------------
 4     instance-00000002              running

$ sudo virsh dumpxml 4
&amp;lt;domain type=&#39;kvm&#39; id=&#39;4&#39;&amp;gt;
  &amp;lt;name&amp;gt;instance-00000002&amp;lt;/name&amp;gt;
  &amp;lt;vcpu placement=&#39;static&#39;&amp;gt;1&amp;lt;/vcpu&amp;gt;
  ...
  &amp;lt;cputune&amp;gt;
    &amp;lt;shares&amp;gt;1024&amp;lt;/shares&amp;gt;
    &amp;lt;vcpupin vcpu=&#39;0&#39; cpuset=&#39;1&#39;/&amp;gt;
    &amp;lt;emulatorpin cpuset=&#39;1&#39;/&amp;gt;
  &amp;lt;/cputune&amp;gt;
  &amp;lt;numatune&amp;gt;
    &amp;lt;memory mode=&#39;strict&#39; nodeset=&#39;0&#39;/&amp;gt;
    &amp;lt;memnode cellid=&#39;0&#39; mode=&#39;strict&#39; nodeset=&#39;0&#39;/&amp;gt;
  &amp;lt;/numatune&amp;gt;
  ...
&amp;lt;/domain&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;result&#34;&gt;Result&lt;/h1&gt;

&lt;p&gt;The image metadata is being loaded as expected. No issues here.&lt;/p&gt;

&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.openstack.org/admin-guide/compute-flavors.html&#34;&gt;OpenStack Administrator Guide: Compute flavors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.openstack.org/admin-guide/compute-numa-cpu-pinning.html&#34;&gt;OpenStack Administrator Guide: Enabling advanced CPU topologies in
guests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.openstack.org/image-guide/image-metadata.html&#34;&gt;OpenStack Virtual Machine Image Guide: Image metadata&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Configuring ZNC with HexChat</title>
      <link>https://that.guru/blog/znc-sasl-server-pass/</link>
      <pubDate>Sun, 26 Jun 2016 14:00:39 +0100</pubDate>
      
      <guid>https://that.guru/blog/znc-sasl-server-pass/</guid>
      <description>

&lt;h1 id=&#34;configuring-znc-with-hexchat&#34;&gt;Configuring ZNC with HexChat&lt;/h1&gt;

&lt;p&gt;I recently set up ZNC instance to capture whatever I may miss when not
connected to any of the many &lt;a href=&#34;https://wiki.openstack.org/wiki/IRC&#34;&gt;OpenStack IRC&lt;/a&gt; channels. One
tricky part of this configuration was my use of multiple authentication layers.
I have ZNC configured to use a server password, but I also have my nick
&lt;a href=&#34;https://freenode.net/kb/answer/registration&#34;&gt;registered on freenode&lt;/a&gt; and I would like to use
&lt;a href=&#34;https://freenode.net/kb/answer/sasl&#34;&gt;SASL&lt;/a&gt; to authenticate this. It turns out that this is
relatively easy to do.&lt;/p&gt;

&lt;h2 id=&#34;configure-server-password-pass-authentication&#34;&gt;Configure server password (/PASS) authentication&lt;/h2&gt;

&lt;p&gt;You should first configure the connection to your ZNC server. Create a new
server profile (&lt;em&gt;HexChat&lt;/em&gt; &amp;gt; &lt;em&gt;Network List&lt;/em&gt;, or &lt;code&gt;&amp;lt;Ctrl&amp;gt;&lt;/code&gt; + &lt;code&gt;S&lt;/code&gt;) and
configure it like so:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/znc-sasl-server-pass-1.png&#34;  /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Configuring server password authentication&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;p&gt;Most of this configuration doesn&amp;rsquo;t differ from the many guides available on
configuring HexChat with ZNC. I&amp;rsquo;m using SSL, so I enable that (and accept my
&amp;ldquo;invalid&amp;rdquo;, self-signed key), and I select this as the server to automatically
connect to when I open HexChat. The interesting bit is the &lt;code&gt;Server Password
&amp;lt;/PASS password&lt;/code&gt; section. In here, I have my username and server password
stored in format &lt;code&gt;[username]:[password]&lt;/code&gt;, e.g. &lt;code&gt;admin:password&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Once done, I also need to configure a channels you want to connect to on the
&lt;em&gt;Autojoin channels&lt;/em&gt; tab:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://that.guru/media/znc-sasl-server-pass-2.png&#34;  /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Configuring autojoin channels&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;p&gt;I&amp;rsquo;m mostly concerned with &lt;code&gt;#openstack-xxx&lt;/code&gt; channels, but your configuration
will differ.&lt;/p&gt;

&lt;h2 id=&#34;configure-sasl-authentication&#34;&gt;Configure SASL authentication&lt;/h2&gt;

&lt;p&gt;Now we should be able to connect to the ZNC server without gettings an &lt;code&gt;Invalid
password&lt;/code&gt; errors. However, looking at the logs for the &lt;em&gt;freenode&lt;/em&gt; server
connection, we can see that we&amp;rsquo;re being asked to authenticate our registered
nick:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TODO&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Time for SASL. Many of these steps are documented on the &lt;a href=&#34;http://wiki.znc.in/Sasl&#34;&gt;ZNC wiki&lt;/a&gt;,
but they&amp;rsquo;re documented here for posterity.&lt;/p&gt;

&lt;p&gt;First, &lt;a href=&#34;http://wiki.znc.in/Modules#Managing_Modules&#34;&gt;load the module&lt;/a&gt; on ZNC:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/msg *status loadmodule sasl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, set the mechanism. We use &lt;code&gt;PLAIN&lt;/code&gt; (plaintext), which is a-OK as we&amp;rsquo;re
using SSL:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/msg *sasl mechanism PLAIN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, supply your username and password:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/msg *sasl set &amp;lt;username&amp;gt; &amp;lt;password&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That should be the end the need to run pesky &lt;code&gt;nickserv&lt;/code&gt; commands.&lt;/p&gt;

&lt;h2 id=&#34;wrap-up&#34;&gt;Wrap up&lt;/h2&gt;

&lt;p&gt;We now have authentication against the server, using a server password, and
authentication against the nickserv, using SASL. Pretty much hassle free.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hello, World!</title>
      <link>https://that.guru/blog/hello-world/</link>
      <pubDate>Sat, 25 Jun 2016 18:50:22 +0100</pubDate>
      
      <guid>https://that.guru/blog/hello-world/</guid>
      <description>&lt;p&gt;This is my new, &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo-powered&lt;/a&gt; blog. I have a backlog of articles to
publish, so expect to see lots of material going up here in the next few weeks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://that.guru/blog/how-to-use-git-review/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://that.guru/blog/how-to-use-git-review/</guid>
      <description>

&lt;h1 id=&#34;how-to-use-git-review&#34;&gt;How to use git-review&lt;/h1&gt;

&lt;p&gt;This guide is borrows heavily from the original Openstack guide, found here:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;https://wiki.openstack.org/wiki/Gerrit_Workflow
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;h3 id=&#34;what-is-git-review&#34;&gt;What is &lt;code&gt;git-review&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;git-review&lt;/code&gt; is a Python wrapper for many of the common Git commands used in
conjunction with Gerrit. It encapsulates many of the most common commands used,
in order to speed things up.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s possible to use Gerrit without using the &lt;code&gt;git-review&lt;/code&gt; tool. All the
commands we use below have their plain &lt;code&gt;git&lt;/code&gt; equivalents. However, the question
remains: why would you want to? The &lt;code&gt;git-review&lt;/code&gt; tool speeds things up, and is
used by a number of teams outside Intel (including MediaWiki and OpenStack).&lt;/p&gt;

&lt;h3 id=&#34;a-word-on-workflows&#34;&gt;A word on workflows&lt;/h3&gt;

&lt;p&gt;Gerrit, like Git, is extremely flexible. There is no one true way to work with
it. However, Git has two predominant &amp;ldquo;workflows&amp;rdquo;: the merge workflow, and the
rebase workflow. Each of these have their pros and cons, but both work equally
well with standard Git. This is not the case with Gerrit. While the former
workflow is possible, it&amp;rsquo;s very awkward (Gerrit doesn&amp;rsquo;t handle merge commits
very well). Hence, despite the issues that can occur from &amp;ldquo;rewriting history&amp;rdquo;
in the rebase workflow, it&amp;rsquo;s the best option.&lt;/p&gt;

&lt;h2 id=&#34;initial-steps&#34;&gt;Initial steps&lt;/h2&gt;

&lt;p&gt;First, install the tool. On Fedora 16 and up:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yum install git-review
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Navigate to the project you wish to use, and ensure you can connect to the
Gerrit server:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd &amp;lt;repo&amp;gt;
git review -s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You may get a warning like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;No &#39;.gitreview&#39; file found in this repository.
We don&#39;t know where your gerrit is. Please manually create
a remote named gerrit and try again.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If so, you likely have your Gerrit review server&amp;rsquo;s &amp;ldquo;remote&amp;rdquo; called &lt;code&gt;origin&lt;/code&gt; or
something similar. You can check this like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git remote -v
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You&amp;rsquo;ll likely get something like so, where the url points to a Gerrit project:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;origin  &amp;lt;url&amp;gt; (fetch)
origin  &amp;lt;url&amp;gt; (push)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assuming this is the case, just rename the remote:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git remote rename origin gerrit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If this isn&amp;rsquo;t (i.e. you have more than one remote), you may want to rename
the relevant remote or add a new one for Gerrit:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git remote add gerrit [url]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;using-the-review-tool&#34;&gt;Using the review tool&lt;/h2&gt;

&lt;h3 id=&#34;making-and-uploading-changesets&#34;&gt;Making and uploading changesets&lt;/h3&gt;

&lt;p&gt;Checkout a feature branch using your teams naming conventions:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git checkout -b &amp;lt;topic_branch&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; You should always work on feature branches when working with Gerrit.
If you work on &lt;code&gt;master&lt;/code&gt; or &lt;code&gt;development&lt;/code&gt;, you&amp;rsquo;re going to get merge conflicts
when you pull in the latest changes from Gerrit/upstream.&lt;/p&gt;

&lt;p&gt;Now make some changes: add some new files, delete old ones, do what you have to
do. Following this, save the changes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git commit -as  # this is the same as `git add -u` and `git commit -as`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This should create a new commit. You can upload this changeset like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git remote update  # to get latest changes
git review &amp;lt;upstream_branch&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; This will automatically rebase the change against the upstream master.&lt;/p&gt;

&lt;p&gt;If you now go to Gerrit, you&amp;rsquo;ll see a new changeset there. Its &amp;ldquo;Branch&amp;rdquo; will
correspond with the value of &lt;code&gt;&amp;lt;upstream_branch&amp;gt;&lt;/code&gt;, while the &amp;ldquo;Topic&amp;rdquo; will
correspond with the value of &lt;code&gt;&amp;lt;topic_branch&amp;gt;&lt;/code&gt; (i.e. your local branch).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; In Gerrit, the &amp;ldquo;Branch&amp;rdquo; means the Git branch that the commit is meant
for. However, the &amp;ldquo;Topic&amp;rdquo; has no bearing on the actual underlying repo. Instead
it is merely used to gather similar changes together.&lt;/p&gt;

&lt;h2 id=&#34;reworking-a-changeset&#34;&gt;Reworking a changeset&lt;/h2&gt;

&lt;p&gt;No one&amp;rsquo;s perfect, and neither is your code. When you need to rework some, you
do so using the &lt;code&gt;rebase&lt;/code&gt; and &lt;code&gt;commit --amend&lt;/code&gt; tools. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[make changes...]
git commit -a --amend
git review &amp;lt;upstream_branch&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alternatively&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git rebase -i &amp;lt;ancestor&amp;gt;
[make changes...]
git review &amp;lt;upstream_branch&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; If you delete a commit using rebase, you &lt;em&gt;will&lt;/em&gt; need to manually
abandon it. Unfortunately there doesn&amp;rsquo;t seem to be any way to avoid this.&lt;/p&gt;

&lt;h2 id=&#34;collaboration&#34;&gt;Collaboration&lt;/h2&gt;

&lt;p&gt;If you want to review/rework someone else&amp;rsquo;s changes, it&amp;rsquo;s very easy to do. This
is great for collaboration/pair-programming.&lt;/p&gt;

&lt;p&gt;To check out someone else&amp;rsquo;s code, you&amp;rsquo;ll want the &amp;ldquo;change id&amp;rdquo;. When you have
this, just use the following change:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git review -d &amp;lt;change_id&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will checkout the change, and all changes that it depends on (i.e. the
branch).&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>